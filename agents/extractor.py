import json
import os
from openai import OpenAI, OpenAIError
from typing import Dict, List, Optional
from tenacity import retry, stop_after_attempt, wait_fixed, RetryError
import streamlit as st # Use streamlit for showing errors/warnings

# Import config variables
from config import API_KEY, API_BASE_URL, MODEL_NAME, MIN_STAKEHOLDERS, MAX_STAKEHOLDERS, STAKEHOLDER_ANALYSIS, DECISION_TYPES

# Initialize OpenAI client
client = OpenAI(
    base_url=API_BASE_URL,
    api_key=API_KEY
)

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def _make_extraction_api_call(prompt: str) -> Optional[Dict]:
    """Makes the API call to the LLM for extraction with retries."""
    try:
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are an expert assistant specialized in analyzing decision-making scenarios. Your task is to extract key structural elements from the provided text and format them as a valid JSON object."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4, # Slightly lower temp for more deterministic extraction
            max_tokens=1500, # Increased token limit for potentially complex structures
            response_format={"type": "json_object"} # Request JSON output directly
        )
        response_content = completion.choices[0].message.content
        # print(f"LLM Raw Extraction Response:\n{response_content[:500]}...") # Debugging
        return json.loads(response_content)
    except json.JSONDecodeError as e:
        st.warning(f"LLM response was not valid JSON: {e}. Raw response: {response_content[:500]}...", icon="‚ö†Ô∏è")
        # print(f"JSONDecodeError: {e}. Response: {response_content}") # Debugging
        return None # Return None to indicate failure after retries
    except OpenAIError as e:
        st.error(f"API Error during extraction: {e}", icon="üö®")
        # print(f"OpenAIError: {e}") # Debugging
        raise # Reraise to trigger tenacity retry
    except Exception as e:
        st.error(f"Unexpected error during extraction API call: {e}", icon="üö®")
        # print(f"Unexpected API Error: {e}") # Debugging
        raise # Reraise unexpected errors


def _validate_and_clean_stakeholders(stakeholders: List[Dict]) -> List[Dict]:
    """Ensures stakeholder list meets criteria and cleans data."""
    if not isinstance(stakeholders, list):
        st.warning("LLM did not return a list for stakeholders. Using defaults.", icon="‚ö†Ô∏è")
        return []

    unique_stakeholders = []
    seen_names = set()

    for i, s in enumerate(stakeholders):
        if not isinstance(s, dict):
             st.warning(f"Stakeholder item {i} is not a dictionary. Skipping.", icon="‚ö†Ô∏è")
             continue

        # Basic name and role validation/defaulting
        name = s.get("name", f"Stakeholder {i+1} (Auto-Generated)")
        role = s.get("role", f"Participant {i+1} (Auto-Generated)")

        # Ensure unique names (simple approach)
        original_name = name
        counter = 1
        while name in seen_names:
            name = f"{original_name} {counter}"
            counter += 1
        seen_names.add(name)

        # Validate/default other fields using suggestions from config
        traits = s.get("psychological_traits", [])
        if not isinstance(traits, list): traits = [str(traits)] # Handle non-list traits
        traits = traits or [random.choice(STAKEHOLDER_ANALYSIS["psychological_traits"])] # Ensure at least one

        influences = s.get("influences", [])
        if not isinstance(influences, list): influences = [str(influences)]
        influences = influences or [random.choice(STAKEHOLDER_ANALYSIS["influences"])]

        biases = s.get("biases", [])
        if not isinstance(biases, list): biases = [str(biases)]
        biases = biases or [random.choice(STAKEHOLDER_ANALYSIS["biases"])]

        historical_behavior = s.get("historical_behavior", random.choice(STAKEHOLDER_ANALYSIS["historical_behavior"]))
        if not isinstance(historical_behavior, str): historical_behavior = str(historical_behavior)

        # Use default bio if missing or clearly placeholder
        bio = s.get("bio", "")
        if not bio or "placeholder" in bio.lower() or "N/A" in bio:
             bio = f"{name}, the {role}, brings relevant experience to the discussion. (Auto-Generated)"
        if not isinstance(bio, str): bio = str(bio)


        unique_stakeholders.append({
            "name": name,
            "role": role,
            "psychological_traits": traits,
            "influences": influences,
            "biases": biases,
            "historical_behavior": historical_behavior,
            "bio": bio.strip()
            # Tone and Goals will be generated by persona_builder
        })

        if len(unique_stakeholders) >= MAX_STAKEHOLDERS:
            break # Stop if max stakeholders reached

    # Ensure minimum number of stakeholders
    while len(unique_stakeholders) < MIN_STAKEHOLDERS:
        i = len(unique_stakeholders)
        name = f"Stakeholder {i+1} (Auto-Added)"
        role = f"Participant {i+1} (Auto-Added)"
        counter = 1
        original_name = name
        while name in seen_names: # Ensure uniqueness even for added ones
            name = f"{original_name} {counter}"
            counter += 1
        seen_names.add(name)

        unique_stakeholders.append({
            "name": name,
            "role": role,
            "psychological_traits": [random.choice(STAKEHOLDER_ANALYSIS["psychological_traits"])],
            "influences": [random.choice(STAKEHOLDER_ANALYSIS["influences"])],
            "biases": [random.choice(STAKEHOLDER_ANALYSIS["biases"])],
            "historical_behavior": random.choice(STAKEHOLDER_ANALYSIS["historical_behavior"]),
            "bio": f"{name}, the {role}, added to meet participation requirements. (Auto-Added)"
        })

    return unique_stakeholders


def extract_decision_structure(dilemma: str, process_hint: str, context_text: Optional[str] = None) -> Optional[Dict]:
    """
    Extracts a decision structure from user inputs using an LLM.

    Args:
        dilemma (str): The core decision problem description.
        process_hint (str): Details about the process, stakeholders, timeline, etc.
        context_text (Optional[str]): Additional context (e.g., from PDF).

    Returns:
        Optional[Dict]: Extracted decision structure including decision_type, stakeholders,
                        issues, process, external_factors, or None if extraction fails.
    """
    full_context = f"Decision Dilemma:\n{dilemma}\n\nProcess/Stakeholder Hints:\n{process_hint}"
    if context_text:
        full_context += f"\n\nAdditional Context:\n{context_text[:2000]}..." # Limit context length

    # Construct the prompt for the LLM
    prompt = (
        "Please analyze the following decision scenario and extract its key components "
        f"into a JSON object. Ensure the JSON structure is valid.\n\n"
        f"Scenario Context:\n```\n{full_context}\n```\n\n"
        "JSON Output Structure Requirements:\n"
        "1. `decision_type`: (String) Classify the decision (e.g., " + ", ".join(DECISION_TYPES) + "). Choose the most fitting type.\n"
        "2. `stakeholders`: (List of Objects) Identify key stakeholders involved. "
        f"Aim for {MIN_STAKEHOLDERS}-{MAX_STAKEHOLDERS} distinct individuals/roles. Each object should have:\n"
        "   - `name`: (String) Name of the stakeholder or role.\n"
        "   - `role`: (String) Their title or function in this decision.\n"
        "   - `psychological_traits`: (List of Strings) Infer 1-3 key personality/behavioral traits (e.g., " + ", ".join(STAKEHOLDER_ANALYSIS['psychological_traits'][:3]) + ").\n"
        "   - `influences`: (List of Strings) Infer 1-3 factors influencing their perspective (e.g., " + ", ".join(STAKEHOLDER_ANALYSIS['influences'][:3]) + ").\n"
        "   - `biases`: (List of Strings) Infer 1-2 potential cognitive biases (e.g., " + ", ".join(STAKEHOLDER_ANALYSIS['biases'][:3]) + ").\n"
        "   - `historical_behavior`: (String) Briefly describe their typical decision-making pattern (e.g., " + STAKEHOLDER_ANALYSIS['historical_behavior'][0] + ").\n"
        "   - `bio`: (String) A brief, inferred background relevant to the decision (1-2 sentences).\n"
        "3. `key_issues`: (List of Strings) Identify 2-4 core issues, conflicts, or questions at the heart of the dilemma.\n"
        "4. `process_steps`: (List of Strings) Outline 3-5 key steps in the decision-making process mentioned or implied.\n"
        "5. `external_factors`: (List of Strings) List 1-3 significant external factors impacting the decision (e.g., market conditions, regulations).\n\n"
        "Generate only the JSON object as your response."
    )

    try:
        with st.spinner("Analyzing decision context and extracting structure..."):
            extracted_data = _make_extraction_api_call(prompt)

        if not extracted_data or not isinstance(extracted_data, dict):
            st.error("Failed to extract decision structure after multiple attempts.", icon="üö®")
            return None # Indicate failure

        # --- Validate and Clean Extracted Data ---
        decision_type = extracted_data.get("decision_type", "Strategic") # Default type
        if decision_type not in DECISION_TYPES:
            st.warning(f"Extracted decision type '{decision_type}' not in standard list. Using '{decision_type}'.", icon="‚ö†Ô∏è")
            # Optionally force it into the list or keep the extracted one

        stakeholders = _validate_and_clean_stakeholders(extracted_data.get("stakeholders", []))
        if not stakeholders: # If cleaning failed or returned empty
             st.error("Failed to identify or generate valid stakeholders.", icon="üö®")
             return None # Cannot proceed without stakeholders


        key_issues = extracted_data.get("key_issues", ["Resource Allocation", "Timeline"]) # Default issues
        if not isinstance(key_issues, list) or len(key_issues) == 0:
            st.warning("Could not extract key issues. Using defaults.", icon="‚ö†Ô∏è")
            key_issues = ["Resource Allocation", "Timeline"]


        process_steps = extracted_data.get("process_steps", ["Initial Discussion", "Option Analysis", "Final Decision"]) # Default process
        if not isinstance(process_steps, list) or len(process_steps) == 0:
             st.warning("Could not extract process steps. Using defaults.", icon="‚ö†Ô∏è")
             process_steps = ["Initial Discussion", "Option Analysis", "Final Decision"]

        external_factors = extracted_data.get("external_factors", ["Market Trends"]) # Default factors
        if not isinstance(external_factors, list): # Allow empty list
             external_factors = ["Market Trends"]


        # Return the structured data
        return {
            "decision_type": decision_type,
            "stakeholders": stakeholders,
            "key_issues": key_issues,
            "process_steps": process_steps,
            "external_factors": external_factors,
            # ASCII versions removed, visualizations handled by visualizer.py and Plotly/agraph in app.py
        }

    except RetryError:
        st.error("Extraction API call failed after multiple retries.", icon="üö®")
        return None
    except Exception as e:
        st.error(f"An unexpected error occurred during decision structure extraction: {e}", icon="üö®")
        # print(f"Extraction Main Error: {e}") # Debugging
        return None


# Removed generate_ascii_process and generate_ascii_stakeholders as visualization is handled elsewhere.
